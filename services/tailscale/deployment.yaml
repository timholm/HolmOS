apiVersion: v1
kind: Namespace
metadata:
  name: tailscale
---
apiVersion: v1
kind: Secret
metadata:
  name: tailscale-auth
  namespace: tailscale
stringData:
  # Generate auth key at: https://login.tailscale.com/admin/settings/keys
  # Use a reusable, ephemeral key for automatic re-authentication
  AUTH_KEY: "tskey-auth-REPLACE_ME"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tailscale
  namespace: tailscale
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: tailscale
  namespace: tailscale
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["create", "get", "update", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: tailscale
  namespace: tailscale
subjects:
  - kind: ServiceAccount
    name: tailscale
    namespace: tailscale
roleRef:
  kind: Role
  name: tailscale
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tailscale-subnet-router
  namespace: tailscale
  labels:
    app: tailscale
spec:
  replicas: 1
  selector:
    matchLabels:
      app: tailscale
  template:
    metadata:
      labels:
        app: tailscale
    spec:
      serviceAccountName: tailscale
      containers:
        - name: tailscale
          image: tailscale/tailscale:latest
          imagePullPolicy: Always
          env:
            - name: TS_AUTHKEY
              valueFrom:
                secretKeyRef:
                  name: tailscale-auth
                  key: AUTH_KEY
            - name: TS_KUBE_SECRET
              value: "tailscale-state"
            - name: TS_USERSPACE
              value: "false"
            - name: TS_ROUTES
              # K3s default CIDRs - adjust if using different ranges
              # Pod CIDR: 10.42.0.0/16, Service CIDR: 10.43.0.0/16
              # Also include local network for full cluster access
              value: "10.42.0.0/16,10.43.0.0/16,192.168.8.0/24"
            - name: TS_EXTRA_ARGS
              value: "--hostname=holmos-cluster --accept-routes"
          securityContext:
            capabilities:
              add:
                - NET_ADMIN
          resources:
            requests:
              memory: "64Mi"
              cpu: "50m"
            limits:
              memory: "128Mi"
              cpu: "200m"
      nodeSelector:
        # Run on control plane for stability
        node-role.kubernetes.io/control-plane: "true"
      tolerations:
        - key: "node-role.kubernetes.io/control-plane"
          operator: "Exists"
          effect: "NoSchedule"
